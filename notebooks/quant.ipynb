{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==2.15.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets==2.15.0) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets==2.15.0) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets==2.15.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets==2.15.0) (0.3.7)\n",
      "Requirement already satisfied: pandas in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets==2.15.0) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets==2.15.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets==2.15.0) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets==2.15.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets==2.15.0) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15.0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets==2.15.0) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets==2.15.0) (0.20.3)\n",
      "Requirement already satisfied: packaging in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets==2.15.0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets==2.15.0) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets==2.15.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets==2.15.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets==2.15.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets==2.15.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets==2.15.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets==2.15.0) (4.0.3)\n",
      "Requirement already satisfied: filelock in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.18.0->datasets==2.15.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.18.0->datasets==2.15.0) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.15.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.15.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.15.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.15.0) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from pandas->datasets==2.15.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from pandas->datasets==2.15.0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from pandas->datasets==2.15.0) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.15.0) (1.16.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://huggingface.github.io/autogptq-index/whl/cu117/\n",
      "Requirement already satisfied: auto-gptq in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (0.7.1)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from auto-gptq) (0.28.0)\n",
      "Requirement already satisfied: datasets in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from auto-gptq) (2.15.0)\n",
      "Requirement already satisfied: sentencepiece in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from auto-gptq) (0.1.99)\n",
      "Requirement already satisfied: numpy in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from auto-gptq) (1.26.3)\n",
      "Requirement already satisfied: rouge in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from auto-gptq) (1.0.1)\n",
      "Requirement already satisfied: gekko in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from auto-gptq) (1.0.7)\n",
      "Requirement already satisfied: torch>=1.13.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from auto-gptq) (2.2.1)\n",
      "Requirement already satisfied: safetensors in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from auto-gptq) (0.4.2)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from auto-gptq) (4.38.2)\n",
      "Requirement already satisfied: peft>=0.5.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from auto-gptq) (0.9.0)\n",
      "Requirement already satisfied: tqdm in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from auto-gptq) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from accelerate>=0.26.0->auto-gptq) (23.1)\n",
      "Requirement already satisfied: psutil in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from accelerate>=0.26.0->auto-gptq) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from accelerate>=0.26.0->auto-gptq) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from accelerate>=0.26.0->auto-gptq) (0.20.3)\n",
      "Requirement already satisfied: filelock in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from torch>=1.13.0->auto-gptq) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from torch>=1.13.0->auto-gptq) (4.9.0)\n",
      "Requirement already satisfied: sympy in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from torch>=1.13.0->auto-gptq) (1.12)\n",
      "Requirement already satisfied: networkx in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from torch>=1.13.0->auto-gptq) (3.1)\n",
      "Requirement already satisfied: jinja2 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from torch>=1.13.0->auto-gptq) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from torch>=1.13.0->auto-gptq) (2023.10.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from transformers>=4.31.0->auto-gptq) (2023.10.3)\n",
      "Requirement already satisfied: requests in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from transformers>=4.31.0->auto-gptq) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from transformers>=4.31.0->auto-gptq) (0.15.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets->auto-gptq) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets->auto-gptq) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets->auto-gptq) (0.3.7)\n",
      "Requirement already satisfied: pandas in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets->auto-gptq) (2.1.3)\n",
      "Requirement already satisfied: xxhash in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets->auto-gptq) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets->auto-gptq) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from datasets->auto-gptq) (3.9.3)\n",
      "Requirement already satisfied: six in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from rouge->auto-gptq) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets->auto-gptq) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets->auto-gptq) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets->auto-gptq) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets->auto-gptq) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from requests->transformers>=4.31.0->auto-gptq) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from requests->transformers>=4.31.0->auto-gptq) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from requests->transformers>=4.31.0->auto-gptq) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from requests->transformers>=4.31.0->auto-gptq) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from pandas->datasets->auto-gptq) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from pandas->datasets->auto-gptq) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U transformers peft accelerate optimum\n",
    "!pip install datasets==2.15.0\n",
    "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu117/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:57:56.151900: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-13 13:57:56.151925: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-13 13:57:56.152520: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-13 13:57:56.156296: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 13:57:57.205114: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /users/eleves-b/2021/guilherme.vieira-\n",
      "[nltk_data]     manhaes/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /users/eleves-b/2021/guilherme.vieira-\n",
      "[nltk_data]     manhaes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM,GPTQConfig, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "from peft import LoraConfig,prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "crop = True\n",
    "remove_stopwords=False\n",
    "finetune_att=True\n",
    "finetune_lin=True\n",
    "crop_size=0.3\n",
    "batch_size = 8\n",
    "num_train_epochs = 3\n",
    "max_input_length = 1024\n",
    "max_target_length = 256\n",
    "model_id = \"google/mt5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Block pattern could not be match. Pass `block_name_to_quantize` argument in `quantize_model`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m quantization_config \u001b[38;5;241m=\u001b[39m GPTQConfig(\n\u001b[1;32m      2\u001b[0m     bits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m      3\u001b[0m     desc_act\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     max_input_length\u001b[38;5;241m=\u001b[39mmax_input_length\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    560\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/modeling_utils.py:3561\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3558\u001b[0m     dispatch_model(model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdevice_map_kwargs)\n\u001b[1;32m   3560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3561\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocess_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3562\u001b[0m     model\u001b[38;5;241m.\u001b[39mhf_quantizer \u001b[38;5;241m=\u001b[39m hf_quantizer\n\u001b[1;32m   3564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _adapter_model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/quantizers/base.py:179\u001b[0m, in \u001b[0;36mHfQuantizer.postprocess_model\u001b[0;34m(self, model, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpostprocess_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedModel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    Post-process the model post weights loading.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    Make sure to override the abstract method `_process_model_after_weight_loading`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m            The keyword arguments that are passed along `_process_model_after_weight_loading`.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_model_after_weight_loading\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/quantizers/quantizer_gptq.py:85\u001b[0m, in \u001b[0;36mGptqHfQuantizer._process_model_after_weight_loading\u001b[0;34m(self, model, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantization_config\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantization_config\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mname_or_path\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimum_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mquantization_config \u001b[38;5;241m=\u001b[39m GPTQConfig\u001b[38;5;241m.\u001b[39mfrom_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimum_quantizer\u001b[38;5;241m.\u001b[39mto_dict())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/optimum/gptq/quantizer.py:397\u001b[0m, in \u001b[0;36mGPTQQuantizer.quantize_model\u001b[0;34m(self, model, tokenizer)\u001b[0m\n\u001b[1;32m    394\u001b[0m layer_input_kwargs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_name_to_quantize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_name_to_quantize \u001b[38;5;241m=\u001b[39m \u001b[43mget_block_name_with_pattern\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_name_preceding_first_block \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_name_preceding_first_block \u001b[38;5;241m=\u001b[39m get_preceding_modules(model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_name_to_quantize)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/optimum/gptq/utils.py:77\u001b[0m, in \u001b[0;36mget_block_name_with_pattern\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(pattern_candidate \u001b[38;5;129;01min\u001b[39;00m name \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules_names):\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pattern_candidate\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlock pattern could not be match. Pass `block_name_to_quantize` argument in `quantize_model`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Block pattern could not be match. Pass `block_name_to_quantize` argument in `quantize_model`"
     ]
    }
   ],
   "source": [
    "quantization_config = GPTQConfig(\n",
    "    bits=4,\n",
    "    desc_act=False,\n",
    "    dataset=[\"hey\"],\n",
    "    group_size=128,\n",
    "    max_input_length=max_input_length\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_id, \n",
    "    quantization_config=quantization_config, \n",
    "    device_map='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour je m'appele Bonjour.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text = \"Bonjour je m'appele\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(0)\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bac17441c784d9cb917f3dafee1282d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d41f46f5e5b4a098704a7c78818ce32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82204d98d2a044f1950df011b320a2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720cc6be57a3403289f76c5908a7fa06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def crop_data(file, perc=crop_size):\n",
    "  df = pd.read_csv(f'{file}.csv')\n",
    "  cropped_df = df.sample(int(len(df)*perc))\n",
    "  cropped_df.to_csv(f'{file}-crop.csv', index=False)\n",
    "\n",
    "crop_data(\"../data/train\")\n",
    "crop_data(\"../data/validation\")\n",
    "dataset = load_dataset('csv', data_files={'train': '../data/train-crop.csv', 'validation': '../data/validation-crop.csv'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_stopwords = stopwords.words('french')\n",
    "stopword_ids = set(tokenizer.convert_tokens_to_ids(french_stopwords))\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    formatted_texts = [f\"summarize: {text}\" for text in examples[\"text\"]]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        formatted_texts,\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        examples[\"titles\"], max_length=max_target_length, truncation=True\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251a92b1375e4d98a9800d74d2195879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6420 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d4038028d64256a3159e35cfb2beb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_score = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,142,544 || all params: 262,029,328 || trainable%: 1.9625833639507713\n"
     ]
    }
   ],
   "source": [
    "att_target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\"]\n",
    "import re\n",
    "pattern = r'\\((\\w+)\\): Linear'\n",
    "linear_layers = re.findall(pattern, str(model.modules))\n",
    "lin_target_modules = list(set(linear_layers))\n",
    "\n",
    "target_modules = []\n",
    "if finetune_att: target_modules.extend(att_target_modules)\n",
    "if finetune_lin: target_modules.extend(lin_target_modules)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules = target_modules,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    result = rouge_score.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quant_method': <QuantizationMethod.GPTQ: 'gptq'>,\n",
       " 'bits': 4,\n",
       " 'tokenizer': None,\n",
       " 'dataset': ['hey'],\n",
       " 'group_size': 128,\n",
       " 'damp_percent': 0.1,\n",
       " 'desc_act': False,\n",
       " 'sym': True,\n",
       " 'true_sequential': True,\n",
       " 'use_cuda_fp16': False,\n",
       " 'model_seqlen': None,\n",
       " 'block_name_to_quantize': None,\n",
       " 'module_name_preceding_first_block': None,\n",
       " 'batch_size': 1,\n",
       " 'pad_token_id': None,\n",
       " 'use_exllama': True,\n",
       " 'max_input_length': None,\n",
       " 'exllama_config': {'version': <ExllamaVersion.ONE: 1>},\n",
       " 'cache_block_outputs': True,\n",
       " 'modules_in_block_to_quantize': None}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.quantization_config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=2,\n",
    "    max_steps=10,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=1,\n",
    "    output_dir=\"outputs\",\n",
    "    optim=\"adamw_hf\"\n",
    ")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2021/guilherme.vieira-manhaes/miniconda3/lib/python3.9/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempting to unscale FP16 gradients.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:2003\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1998\u001b[0m     _grad_norm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\n\u001b[1;32m   1999\u001b[0m         amp\u001b[38;5;241m.\u001b[39mmaster_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer),\n\u001b[1;32m   2000\u001b[0m         args\u001b[38;5;241m.\u001b[39mmax_grad_norm,\n\u001b[1;32m   2001\u001b[0m     )\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2003\u001b[0m     _grad_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2005\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2006\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2009\u001b[0m     is_accelerate_available()\n\u001b[1;32m   2010\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2011\u001b[0m ):\n\u001b[1;32m   2012\u001b[0m     grad_norm \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_global_grad_norm()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py:2145\u001b[0m, in \u001b[0;36mAccelerator.clip_grad_norm_\u001b[0;34m(self, parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m   2143\u001b[0m             \u001b[38;5;66;03m# Set is_xla_gradients_synced to True to avoid all-reduce twice in the AcceleratedOptimizer step.\u001b[39;00m\n\u001b[1;32m   2144\u001b[0m             acc_opt\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 2145\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munscale_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(parameters, max_norm, norm_type\u001b[38;5;241m=\u001b[39mnorm_type)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py:2095\u001b[0m, in \u001b[0;36mAccelerator.unscale_gradients\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m   2093\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(opt, AcceleratedOptimizer):\n\u001b[1;32m   2094\u001b[0m     opt \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39moptimizer\n\u001b[0;32m-> 2095\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munscale_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:336\u001b[0m, in \u001b[0;36mGradScaler.unscale_\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m    333\u001b[0m inv_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale\u001b[38;5;241m.\u001b[39mdouble()\u001b[38;5;241m.\u001b[39mreciprocal()\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    334\u001b[0m found_inf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((), \u001b[38;5;241m0.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 336\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unscale_grads_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    338\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mUNSCALED\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:258\u001b[0m, in \u001b[0;36mGradScaler._unscale_grads_\u001b[0;34m(self, optimizer, inv_scale, found_inf, allow_fp16)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m allow_fp16) \u001b[38;5;129;01mand\u001b[39;00m param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to unscale FP16 gradients.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mis_sparse:\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# is_coalesced() == False means the sparse grad has values with duplicate indices.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# coalesce() deduplicates indices and adds all values that have the same index.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# For scaled fp16 values, there's a good chance coalescing will cause overflow,\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;66;03m# so we should check the coalesced _values().\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfloat16:\n",
      "\u001b[0;31mValueError\u001b[0m: Attempting to unscale FP16 gradients."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
