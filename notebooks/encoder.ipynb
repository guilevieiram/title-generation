{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /users/eleves-b/2021/guilherme.vieira-\n",
      "[nltk_data]     manhaes/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from titlegen.score import avg_score\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BatchEncoding\n",
    "from transformers import CamembertModel, CamembertTokenizer\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('../data/validation.csv')\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text_sents'] = train_df['text'].apply(lambda x: sent_tokenize(x, language='french'))\n",
    "validation_df['text_sents'] = validation_df['text'].apply(lambda x: sent_tokenize(x, language='french'))\n",
    "test_df['text_sents'] = test_df['text'].apply(lambda x: sent_tokenize(x, language='french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['titles_sents'] = train_df['titles'].apply(lambda x: sent_tokenize(x, language='french'))\n",
    "validation_df['titles_sents'] = validation_df['titles'].apply(lambda x: sent_tokenize(x, language='french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>titles</th>\n",
       "      <th>text_sents</th>\n",
       "      <th>titles_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sur les réseaux sociaux, les images sont impre...</td>\n",
       "      <td>Le bateau de croisière, long de 275 m, a percu...</td>\n",
       "      <td>[Sur les réseaux sociaux, les images sont impr...</td>\n",
       "      <td>[Le bateau de croisière, long de 275 m, a perc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La vidéo est devenue virale. Elle montre un po...</td>\n",
       "      <td>Le parquet de Paris a annoncé vendredi avoir o...</td>\n",
       "      <td>[La vidéo est devenue virale., Elle montre un ...</td>\n",
       "      <td>[Le parquet de Paris a annoncé vendredi avoir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Depuis la présidentielle, il est parfois un pe...</td>\n",
       "      <td>À Trappes (Yvelines), c'est désormais la star....</td>\n",
       "      <td>[Depuis la présidentielle, il est parfois un p...</td>\n",
       "      <td>[À Trappes (Yvelines), c'est désormais la star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Routes endommagées, trains toujours perturbés,...</td>\n",
       "      <td>Un homme de 44 ans est porté disparu depuis sa...</td>\n",
       "      <td>[Routes endommagées, trains toujours perturbés...</td>\n",
       "      <td>[Un homme de 44 ans est porté disparu depuis s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Une enquête menée par le journal l'Obs.La nuit...</td>\n",
       "      <td>Son nom n'avait jusque-là jamais été cité dans...</td>\n",
       "      <td>[Une enquête menée par le journal l'Obs.La nui...</td>\n",
       "      <td>[Son nom n'avait jusque-là jamais été cité dan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Sur les réseaux sociaux, les images sont impre...   \n",
       "1  La vidéo est devenue virale. Elle montre un po...   \n",
       "2  Depuis la présidentielle, il est parfois un pe...   \n",
       "3  Routes endommagées, trains toujours perturbés,...   \n",
       "4  Une enquête menée par le journal l'Obs.La nuit...   \n",
       "\n",
       "                                              titles  \\\n",
       "0  Le bateau de croisière, long de 275 m, a percu...   \n",
       "1  Le parquet de Paris a annoncé vendredi avoir o...   \n",
       "2  À Trappes (Yvelines), c'est désormais la star....   \n",
       "3  Un homme de 44 ans est porté disparu depuis sa...   \n",
       "4  Son nom n'avait jusque-là jamais été cité dans...   \n",
       "\n",
       "                                          text_sents  \\\n",
       "0  [Sur les réseaux sociaux, les images sont impr...   \n",
       "1  [La vidéo est devenue virale., Elle montre un ...   \n",
       "2  [Depuis la présidentielle, il est parfois un p...   \n",
       "3  [Routes endommagées, trains toujours perturbés...   \n",
       "4  [Une enquête menée par le journal l'Obs.La nui...   \n",
       "\n",
       "                                        titles_sents  \n",
       "0  [Le bateau de croisière, long de 275 m, a perc...  \n",
       "1  [Le parquet de Paris a annoncé vendredi avoir ...  \n",
       "2  [À Trappes (Yvelines), c'est désormais la star...  \n",
       "3  [Un homme de 44 ans est porté disparu depuis s...  \n",
       "4  [Son nom n'avait jusque-là jamais été cité dan...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id=\"camembert/camembert-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamembertModelAdapted(CamembertModel):\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        **_,\n",
    "    ):\n",
    "        return super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained(model_id)\n",
    "camembert = CamembertModelAdapted.from_pretrained(model_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,555,328 || all params: 340,216,832 || trainable%: 1.0450182547111602\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\", \"key\", \"dense\"],\n",
    "    lora_dropout=0.01,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    ")\n",
    "\n",
    "camembert = get_peft_model(camembert, config)\n",
    "camembert.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, encoder, max_length=512):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.encoder = encoder\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_sentence = self.dataframe.iloc[idx]['text']\n",
    "        output_sentence = self.dataframe.iloc[idx]['titles']\n",
    "\n",
    "        input_tokens = self.tokenizer(\n",
    "            input_sentence, \n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "        input_tokens = BatchEncoding(\n",
    "            {key: val.squeeze(0) for key, val in input_tokens.items()})\n",
    "        \n",
    "        output_tokens = self.tokenizer(\n",
    "            output_sentence, \n",
    "            max_length=self.max_length,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_encoding = self.encoder.base_model.model.embeddings(output_tokens.input_ids)\n",
    "            output_encoding = output_encoding.mean(axis=1).view(-1)\n",
    "            \n",
    "        return input_tokens, output_encoding\n",
    "\n",
    "class EvalDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, encoder, max_length=512):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.encoder = encoder\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_sentences = self.dataframe.iloc[idx]['text_sents']\n",
    "        input_sentence = self.dataframe.iloc[idx]['text']\n",
    "        output_sentence = self.dataframe.iloc[idx]['titles']\n",
    "\n",
    "        input_tokens = self.tokenizer(\n",
    "            input_sentences, \n",
    "            max_length=self.max_length,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_encodings=self.encoder.base_model.model.embeddings(input_tokens.input_ids)\n",
    "            input_encodings=input_encodings.mean(axis=1)\n",
    "\n",
    "        input_tokens_virgin = self.tokenizer(\n",
    "            input_sentence, \n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "\n",
    "\n",
    "        return input_sentences, output_sentence, input_encodings, input_tokens_virgin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_df_sample = train_df.sample(5000).reset_index()\n",
    "val_df_sample = validation_df.sample(500).reset_index()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    TextDataset(train_df_sample, tokenizer, camembert), \n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    TextDataset(val_df_sample, tokenizer, camembert), \n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_dataset = EvalDataset(val_df_sample, tokenizer, camembert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512]) torch.Size([8, 1024])\n",
      "torch.Size([8, 512]) torch.Size([8, 1024])\n",
      "16 213 torch.Size([16, 1024]) torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "for input_toks, outs in train_dataloader:\n",
    "    print(input_toks.input_ids.shape,outs.shape)\n",
    "    break\n",
    "for input_toks, outs in val_dataloader:\n",
    "    print(input_toks.input_ids.shape,outs.shape)\n",
    "    break\n",
    "\n",
    "for in_sents, out_sent, in_encoding, in_tokens in validation_dataset:\n",
    "    print(len(in_sents), len(out_sent), in_encoding.shape, in_tokens.input_ids.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceEmbedder(nn.Module):\n",
    "    def __init__(self, inner_model, embedding_dim=1024):\n",
    "        super(SentenceEmbedder, self).__init__()\n",
    "        self.inner_model = inner_model\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.fc1 = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.fc2 = nn.Linear(embedding_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.inner_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        pooled_output = self.pooling(last_hidden_state.transpose(1, 2)).squeeze(-1)\n",
    "        x = self.fc1(pooled_output)\n",
    "        x = self.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceEmbedder(\n",
       "  (inner_model): PeftModelForSeq2SeqLM(\n",
       "    (base_model): LoraModel(\n",
       "      (model): CamembertModelAdapted(\n",
       "        (embeddings): CamembertEmbeddings(\n",
       "          (word_embeddings): Embedding(32005, 1024, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 1024)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): CamembertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-23): 24 x CamembertLayer(\n",
       "              (attention): CamembertAttention(\n",
       "                (self): CamembertSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.01, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.01, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.01, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): CamembertSelfOutput(\n",
       "                  (dense): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.01, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CamembertIntermediate(\n",
       "                (dense): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): CamembertOutput(\n",
       "                (dense): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): CamembertPooler(\n",
       "          (dense): lora.Linear(\n",
       "            (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.01, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooling): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (gelu): GELU(approximate='none')\n",
       "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceEmbedder(camembert)\n",
    "model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "def validate():\n",
    "    sents = []\n",
    "    titles = []\n",
    "    l = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for in_sents, out_sent, in_encoding, in_tokens in validation_dataset:\n",
    "            out = model(**in_tokens).view(-1)\n",
    "            inner =  in_encoding @ out\n",
    "            best=in_sents[inner.argmax().item()]\n",
    "            sents.append(best)\n",
    "            titles.append(out_sent)\n",
    "\n",
    "        for inputs, outs in val_dataloader:\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs, outs)\n",
    "            l += loss.item()\n",
    "    \n",
    "    model.train()\n",
    "    return avg_score(sents, titles), l/len(val_dataloader)\n",
    "\n",
    "def train():\n",
    "    num_epochs = 5\n",
    "    log_steps = 100\n",
    "    losses = []\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for step, (inputs, outs) in enumerate(train_dataloader):\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs, outs)\n",
    "            loss.backward()\n",
    "            epoch_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if step % log_steps == 0:\n",
    "                print(f\"epoch {epoch+1}/{num_epochs}, step {step+1}/{len(train_dataloader)}, loss={loss.item():.4f}\")\n",
    "        \n",
    "        score, val_loss = validate()\n",
    "        losses.append(epoch_loss)\n",
    "        print(f\"\"\"\n",
    "        epoch {epoch+1}/{num_epochs}, \n",
    "            valloss={val_loss:.4f}, \n",
    "            trainloss={epoch_loss/len(train_dataloader):.4f}, \n",
    "            score={score:.4f}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08938369009210473, 0.017157526923313973)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/5, step 1/625, loss=0.0189\n",
      "epoch 1/5, step 101/625, loss=0.0081\n",
      "epoch 1/5, step 201/625, loss=0.0040\n",
      "epoch 1/5, step 301/625, loss=0.0080\n",
      "epoch 1/5, step 401/625, loss=0.0051\n",
      "epoch 1/5, step 501/625, loss=0.0045\n",
      "epoch 1/5, step 601/625, loss=0.0040\n",
      "\n",
      "        epoch 1/5, \n",
      "            valloss=0.0046, \n",
      "            trainloss=0.0064, \n",
      "            score=0.1450\n",
      "epoch 2/5, step 1/625, loss=0.0042\n",
      "epoch 2/5, step 101/625, loss=0.0047\n",
      "epoch 2/5, step 201/625, loss=0.0050\n",
      "epoch 2/5, step 301/625, loss=0.0052\n",
      "epoch 2/5, step 401/625, loss=0.0053\n",
      "epoch 2/5, step 501/625, loss=0.0057\n",
      "epoch 2/5, step 601/625, loss=0.0058\n",
      "\n",
      "        epoch 2/5, \n",
      "            valloss=0.0046, \n",
      "            trainloss=0.0051, \n",
      "            score=0.1448\n",
      "epoch 3/5, step 1/625, loss=0.0046\n",
      "epoch 3/5, step 101/625, loss=0.0048\n",
      "epoch 3/5, step 201/625, loss=0.0050\n",
      "epoch 3/5, step 301/625, loss=0.0046\n",
      "epoch 3/5, step 401/625, loss=0.0056\n",
      "epoch 3/5, step 501/625, loss=0.0051\n",
      "epoch 3/5, step 601/625, loss=0.0051\n",
      "\n",
      "        epoch 3/5, \n",
      "            valloss=0.0045, \n",
      "            trainloss=0.0051, \n",
      "            score=0.1450\n",
      "epoch 4/5, step 1/625, loss=0.0044\n",
      "epoch 4/5, step 101/625, loss=0.0047\n",
      "epoch 4/5, step 201/625, loss=0.0051\n",
      "epoch 4/5, step 301/625, loss=0.0085\n",
      "epoch 4/5, step 401/625, loss=0.0044\n",
      "epoch 4/5, step 501/625, loss=0.0051\n",
      "epoch 4/5, step 601/625, loss=0.0042\n",
      "\n",
      "        epoch 4/5, \n",
      "            valloss=0.0045, \n",
      "            trainloss=0.0051, \n",
      "            score=0.1450\n",
      "epoch 5/5, step 1/625, loss=0.0055\n",
      "epoch 5/5, step 101/625, loss=0.0057\n",
      "epoch 5/5, step 201/625, loss=0.0046\n",
      "epoch 5/5, step 301/625, loss=0.0041\n",
      "epoch 5/5, step 401/625, loss=0.0048\n",
      "epoch 5/5, step 501/625, loss=0.0055\n",
      "epoch 5/5, step 601/625, loss=0.0042\n",
      "\n",
      "        epoch 5/5, \n",
      "            valloss=0.0045, \n",
      "            trainloss=0.0050, \n",
      "            score=0.1448\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14857079528089628, 0.00442312584763908)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df_sample = validation_df\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    TextDataset(val_df_sample, tokenizer, camembert), \n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_dataset = EvalDataset(val_df_sample, tokenizer, camembert)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
