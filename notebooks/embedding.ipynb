{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /users/eleves-b/2021/guilherme.vieira-\n",
      "[nltk_data]     manhaes/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('../data/validation.csv')\n",
    "train_df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bonjour', ',', 'je', 'm', '`', 'apelle', 'Guile', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"Bonjour, je m`apelle Guile.\", language=\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text_sents'] = train_df['text'].apply(lambda x: sent_tokenize(x, language='french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df['text_sents'] = validation_df['text'].apply(lambda x: sent_tokenize(x, language='french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>titles</th>\n",
       "      <th>text_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thierry Mariani sur la liste du Rassemblement ...</td>\n",
       "      <td>L'information n'a pas été confirmée par l'inté...</td>\n",
       "      <td>[Thierry Mariani sur la liste du Rassemblement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C'est désormais officiel : Alain Juppé n'est p...</td>\n",
       "      <td>Le maire de Bordeaux ne fait plus partie des R...</td>\n",
       "      <td>[C'est désormais officiel : Alain Juppé n'est ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La mesure est décriée par les avocats et les m...</td>\n",
       "      <td>En 2020, les tribunaux d'instance fusionnent a...</td>\n",
       "      <td>[La mesure est décriée par les avocats et les ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dans une interview accordée au Figaro mercredi...</td>\n",
       "      <td>Les médecins jugés \"gros prescripteurs d'arrêt...</td>\n",
       "      <td>[Dans une interview accordée au Figaro mercred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Le préjudice est estimé à 2 millions d'euros. ...</td>\n",
       "      <td>Il aura fallu mobiliser 90 gendarmes pour cett...</td>\n",
       "      <td>[Le préjudice est estimé à 2 millions d'euros....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Thierry Mariani sur la liste du Rassemblement ...   \n",
       "1  C'est désormais officiel : Alain Juppé n'est p...   \n",
       "2  La mesure est décriée par les avocats et les m...   \n",
       "3  Dans une interview accordée au Figaro mercredi...   \n",
       "4  Le préjudice est estimé à 2 millions d'euros. ...   \n",
       "\n",
       "                                              titles  \\\n",
       "0  L'information n'a pas été confirmée par l'inté...   \n",
       "1  Le maire de Bordeaux ne fait plus partie des R...   \n",
       "2  En 2020, les tribunaux d'instance fusionnent a...   \n",
       "3  Les médecins jugés \"gros prescripteurs d'arrêt...   \n",
       "4  Il aura fallu mobiliser 90 gendarmes pour cett...   \n",
       "\n",
       "                                          text_sents  \n",
       "0  [Thierry Mariani sur la liste du Rassemblement...  \n",
       "1  [C'est désormais officiel : Alain Juppé n'est ...  \n",
       "2  [La mesure est décriée par les avocats et les ...  \n",
       "3  [Dans une interview accordée au Figaro mercred...  \n",
       "4  [Le préjudice est estimé à 2 millions d'euros....  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 18:16:15.548940: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-11 18:16:15.548965: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-11 18:16:15.549571: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-11 18:16:15.553336: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 18:16:16.539768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model =  SentenceTransformer(\"dangvantuan/sentence-camembert-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Un avion est en train de décoller.\",\n",
    "          \"Un homme joue d'une grande flûte.\",\n",
    "          \"Un homme étale du fromage râpé sur une pizza.\",\n",
    "          \"Une personne jette un chat au plafond.\",\n",
    "          \"Une personne est en train de plier un morceau de papier.\",\n",
    "          ]\n",
    "\n",
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = torch.tensor(model.encode([\"<pad>\"]), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, embedding_dim = embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sents = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = train_df['text_sents'][:2].apply(lambda x: torch.tensor(model.encode(x), device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0040, -0.1797,  0.0429,  ...,  0.0393,  0.1627,  0.0575],\n",
       "         [-0.0007, -0.1638, -0.1531,  ...,  0.0176,  0.0171,  0.0803],\n",
       "         [-0.0020, -0.2872,  0.0242,  ...,  0.0603, -0.0371,  0.0529],\n",
       "         ...,\n",
       "         [-0.0149,  0.0250,  0.0175,  ...,  0.0523, -0.0266, -0.0365],\n",
       "         [ 0.0403, -0.0288, -0.0806,  ...,  0.1663, -0.0497,  0.1327],\n",
       "         [-0.0327, -0.0042, -0.0528,  ...,  0.0492,  0.1555,  0.0305]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1212, -0.3656,  0.0027,  ...,  0.0868,  0.0333,  0.0712],\n",
       "         [-0.0128, -0.3151, -0.0098,  ..., -0.0376,  0.1096,  0.0345],\n",
       "         [ 0.0843, -0.2349,  0.1499,  ..., -0.0067,  0.0260,  0.1409],\n",
       "         ...,\n",
       "         [-0.0828, -0.1743, -0.0120,  ...,  0.0573,  0.0283,  0.0830],\n",
       "         [-0.0232, -0.0006,  0.0304,  ...,  0.1469, -0.0011,  0.1170],\n",
       "         [ 0.0497, -0.1555,  0.0136,  ..., -0.0176,  0.0851,  0.1304]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD.repeat(max_sents, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(embedding):\n",
    "    n, _ = embedding.shape\n",
    "    t = PAD.repeat(max_sents, 1)\n",
    "    if n < max_sents:\n",
    "        t[:n, :] = embedding\n",
    "    else:\n",
    "        t = embedding[:max_sents]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0040, -0.1797,  0.0429,  ...,  0.0393,  0.1627,  0.0575],\n",
       "         [-0.0007, -0.1638, -0.1531,  ...,  0.0176,  0.0171,  0.0803],\n",
       "         [-0.0020, -0.2872,  0.0242,  ...,  0.0603, -0.0371,  0.0529],\n",
       "         ...,\n",
       "         [-0.1313,  0.0690,  0.0688,  ...,  0.1028,  0.1254,  0.3187],\n",
       "         [-0.1313,  0.0690,  0.0688,  ...,  0.1028,  0.1254,  0.3187],\n",
       "         [-0.1313,  0.0690,  0.0688,  ...,  0.1028,  0.1254,  0.3187]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1212, -0.3656,  0.0027,  ...,  0.0868,  0.0333,  0.0712],\n",
       "         [-0.0128, -0.3151, -0.0098,  ..., -0.0376,  0.1096,  0.0345],\n",
       "         [ 0.0843, -0.2349,  0.1499,  ..., -0.0067,  0.0260,  0.1409],\n",
       "         ...,\n",
       "         [-0.1313,  0.0690,  0.0688,  ...,  0.1028,  0.1254,  0.3187],\n",
       "         [-0.1313,  0.0690,  0.0688,  ...,  0.1028,  0.1254,  0.3187],\n",
       "         [-0.1313,  0.0690,  0.0688,  ...,  0.1028,  0.1254,  0.3187]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(pad(emb) for emb in embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = torch.stack(tuple(pad(emb) for emb in embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32005"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [5, 50, 6], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer(\"je\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad><unk></s>NOTUSED', '<s> L</s>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.batch_decode([[1, 3, 2], [5, 71, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, max_out_len, vocab_size, embed_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.max_out_len = max_out_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.fc = nn.Linear(embed_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Assuming x is of shape (batch_size, max_len, embed_size)\n",
    "        batch_size, max_len, _ = x.shape\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        if max_len < self.max_out_len:\n",
    "            pad_size = self.max_out_len - max_len\n",
    "            pad =  torch.zeros(batch_size, pad_size, self.vocab_size, device=x.device)\n",
    "            x = torch.cat([x, pad], dim=1)\n",
    "        elif max_len > self.max_out_len:\n",
    "            x = x[:, :self.max_out_len, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm  = MyModel(50, model.tokenizer.vocab_size, embedding_dim).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0257,  0.1379, -0.0053,  ..., -0.0098, -0.1397,  0.0512],\n",
       "         [ 0.1126, -0.0018, -0.0338,  ...,  0.1652, -0.0043,  0.0861],\n",
       "         [-0.0268,  0.0823, -0.0430,  ...,  0.0397, -0.1553,  0.0462],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0442,  0.0461,  0.0152,  ...,  0.0500, -0.0554,  0.0354],\n",
       "         [ 0.0585,  0.0606, -0.0103,  ...,  0.0215, -0.1264,  0.0855],\n",
       "         [ 0.0195,  0.0480, -0.0528,  ...,  0.0241, -0.0142, -0.0079],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, features, target):\n",
    "        self.data = dataframe\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        x = torch.tensor(model.encode(self.data.iloc[idx][self.features]))\n",
    "        y = model.tokenizer(self.data.iloc[idx][self.target], max_length=50, padding='max_length', truncation=True)['input_ids']\n",
    "        return (\n",
    "            pad(x).to(device), \n",
    "            torch.stack(tuple(torch.tensor(t, dtype=torch.int64, device=device) for t in y))\n",
    "        )\n",
    "    \n",
    "dataset = CustomDataset(train_df, features='text_sents', target='titles')\n",
    "\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "num_workers = 2\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 8.650711059570312\n",
      "Epoch 2/2, Loss: 8.521456718444824\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mm.parameters(), lr=0.001)\n",
    "num_epochs = 2\n",
    "mm.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in data_loader:\n",
    "        # Forward pass\n",
    "        outputs = mm(inputs)  # Shape of outputs: (batch_size, max_out_len, vocab_size)\n",
    "        outputs = outputs.view(-1, outputs.shape[-1])  # Reshape for cross-entropy loss\n",
    "        targets = targets.view(-1)  # Reshape targets to match output\n",
    "        # print(inputs.shape, targets.shape, outputs.shape)\n",
    "        # print(inputs.device, targets.device, outputs.device)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        # print(loss)\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(validation_df, features='text_sents', target='titles')\n",
    "\n",
    "\n",
    "data_loader_val = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " de de\n",
      "' de\n",
      " de\n",
      "\n",
      "\n",
      "\n",
      " de de''\n",
      "'' de de de de de\n",
      " Un' Un Un\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " de de, de de\n",
      " de de de\n",
      " de\n",
      "\n",
      " de de de de\n",
      "\n",
      "' de\n",
      " de de'\n",
      " de, de\n",
      "\n",
      "\n",
      "\n",
      " de de de de'\n",
      " de' de de\n",
      "e\n",
      " de'\n",
      "\n",
      " de de, de\n",
      " de','\n",
      "'\n",
      "\n",
      " de, de, de la de',\n",
      "\n",
      ",\n",
      "\n",
      "',\n",
      "\n",
      " de', de' de\n",
      "\n",
      " de'' de\n",
      "' de' Le'\n",
      " de de,\n",
      ",,\n",
      "'\n",
      "\n",
      "\n",
      " de de\n",
      " Un\n",
      " de'\n",
      "' La de de de de de\n",
      "\n",
      "'\n",
      " de\n",
      "de de' de\n",
      "'' de de\n",
      " de' de'\n",
      "\n",
      "AGE\n",
      "\n",
      " de\n",
      "',\n",
      "'\n",
      " de\n",
      "' de de de de' de\n",
      "\n",
      "de de\n",
      "\n",
      " Le Le de de\n",
      "'\n",
      " de'\n",
      "'' de'\n",
      " de\n",
      " de de\n",
      "'\n",
      "de\n",
      "'', de\n",
      "\n",
      "ministre de de de,,,' confi,\n",
      " Un'\n",
      " de de de de de de\n",
      " de de'\n",
      ",\n",
      "\n",
      " de\n",
      " Un'' de' homme Le'\n",
      " de de L de\n",
      " de\n",
      "'\n",
      " de de de de,\n",
      " de de\n",
      "' de de\n",
      "\n",
      " de\n",
      "\n",
      " de\n",
      "de de de' de'\n",
      "\n",
      " de'\n",
      " ministre de\n",
      "'' de\n",
      "de, de de de de' de\n",
      " de'\n",
      " de de de de''''\n",
      "'' de de,\n",
      " de\n",
      "\n",
      " de de de de de'\n",
      " de' Le\n",
      " a de\n",
      "\n",
      " Un Un\n",
      "\n",
      " de'\n",
      " de de\n",
      "\n",
      " de de\n",
      "'\n",
      " de ministre\n",
      "'''\n",
      " L' Les de, Shar,'\n",
      "\n",
      " de\n",
      "de de de de de de\n",
      " de\n",
      "'\n",
      " La de de, de' de de de de\n",
      " de' de'' de'\n",
      ",\n",
      " de'\n",
      ",'\n",
      "\n",
      "' La\n",
      "\n",
      "\n",
      " de de de\n",
      " de\n",
      " de' de de'\n",
      "\n",
      " de de de de de' de de,\n",
      "' de\n",
      "''\n",
      " de de de de\n",
      "'\n",
      "' de de\n",
      "'OLOND Un Les\n",
      "''\n",
      " de, de de de de\n",
      ",, de\n",
      "' Météo\n",
      "de Un de\n",
      "\n",
      "\n",
      "de de\n",
      "\n",
      ",'' de\n",
      "'\n",
      " de de de\n",
      "'''\n",
      " Le Le\n",
      " de\n",
      " Un\n",
      " de de\n",
      " de\n",
      "\n",
      ", de de de'\n",
      " de\n",
      " de de de de\n",
      "\n",
      "de de Le de\n",
      " de\n",
      " de\n",
      " Le,,', de\n",
      "de de', de, de\n",
      " de'\n",
      " de\n",
      " de' de de\n",
      "\n",
      "\n",
      " de de'\n",
      " incendie Un de\n",
      "', de L'\n",
      " de\n",
      " de de\n",
      "\n",
      " de\n",
      " de' de\n",
      "de' de\n",
      "' de\n",
      " Un Un Un' de de'\n",
      "de\n",
      "\n",
      "\n",
      "'' de,,' de,'\n",
      " de de\n",
      "\n",
      "\n",
      "\n",
      " Le de\n",
      "'''\n",
      "\n",
      "''\n",
      " de,'\n",
      "''\n",
      " de de' de de\n",
      " de'\n",
      " de de de\n",
      "\n",
      "\n",
      ",''\n",
      "'' Le''\n",
      "' L de de' Le\n",
      "' de'\n",
      "''\n",
      "de de,'' de\n",
      "\n",
      "'' de'\n",
      ",' de'\n",
      " de Le Le\n",
      "''',,''',''\n",
      "' de de,\n",
      "' de de'\n",
      " de de de de\n",
      " de de\n",
      "'\n",
      "\n",
      " de de de\n",
      " de de Le de\n",
      "' de de\n",
      "\n",
      "\n",
      "' de\n",
      ", de,,, de\n",
      " Le de\n",
      "\n",
      " de\n",
      ", de\n",
      "\n",
      "\n",
      ",,\n",
      "\n",
      "''' de, de, de\n",
      "' de de de,' de\n",
      "\n",
      "\n",
      "de de de' de' de'\n",
      "'''' de de\n",
      " de\n",
      "'\n",
      "'\n",
      ",\n",
      "'' Un\n",
      " de deOND'' de de\n",
      "\n",
      "\n",
      "'', de\n",
      " Un\n",
      "\n",
      " de\n",
      "\n",
      "'\n",
      "'''''' de'\n",
      ",,, de\n",
      " de de,' de',\n",
      "'' de de\n",
      "'\n",
      " Un\n",
      "'\n",
      " de\n",
      "' de'' de'\n",
      " de'\n",
      "\n",
      "\n",
      "\n",
      "'' de de de de''''\n",
      "\n",
      "'\n",
      "'\n",
      "\n",
      "\n",
      ", de de\n",
      " Un de Un de''\n",
      " de\n",
      "'' Les de, de'\n",
      "' L'\n",
      "',''\n",
      ", des de'\n",
      " de''' de'\n",
      " de de\n",
      " Un\n",
      "'\n",
      " de\n",
      " de'', de','''\n",
      "', de de de de de\n",
      " de de\n",
      "Un'\n",
      "\n",
      "'\n",
      "de de' de\n",
      "'\n",
      "' de de'\n",
      "\n",
      "\n",
      "\n",
      "de''\n",
      ", de\n",
      "' de de\n",
      "\n",
      " Météo de\n",
      "'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m data_loader_val:\n\u001b[1;32m      2\u001b[0m     out \u001b[38;5;241m=\u001b[39m mm(inputs)\n\u001b[1;32m      3\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(out,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[30], line 17\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(idx):\n\u001b[1;32m     15\u001b[0m     idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 17\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     18\u001b[0m y \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtokenizer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget], max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     pad(x)\u001b[38;5;241m.\u001b[39mto(device), \n\u001b[1;32m     21\u001b[0m     torch\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28mtuple\u001b[39m(torch\u001b[38;5;241m.\u001b[39mtensor(t, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m y))\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:188\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m convert_to_numpy:\n\u001b[0;32m--> 188\u001b[0m                 embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m         all_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[1;32m    192\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(length_sorted_idx)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for inputs, targets in data_loader_val:\n",
    "    out = mm(inputs)\n",
    "    out = torch.argmax(out,dim=-1)\n",
    "    dec = model.tokenizer.batch_decode(out)[0]\n",
    "    dec = (\n",
    "        dec\n",
    "        .replace(\"<s>\", \"\")\n",
    "        .replace(\"<pad>\", \"\")\n",
    "        .replace(\"NOTUSED\", \"\")\n",
    "    )\n",
    "    print(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
